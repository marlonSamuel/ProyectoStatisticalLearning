{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conslusiones\n",
    "\n",
    "#### El analisis exploratorio:\n",
    "* graficando funciones con matplotlib y su paquete pyplot\n",
    "* pandas para manejo de valores nulos, agrupación de datos, calculo de probabilidades y porcentajes.\n",
    "\n",
    "\n",
    "selección de caracteristicas importantes usando herramientas y paquetes de scikit-learn, como:\n",
    "\n",
    "* Feature selecction\n",
    "* Chi2\n",
    "* Ridge\n",
    "* Feature selecction CV\n",
    "\n",
    "realizando una combinación de todas las caracteristicas y evaluando metricas de interés, para la seleccion de las mejores caracteristicas, basandose en la complejidad y reducción de estas.\n",
    "\n",
    "\n",
    "### Modelo árbol de decisión\n",
    "\n",
    "Se uso el paquete scikit-learn tree, DecisionTreeClassifier, para realizar el árbol de desición, investigando los parametros que recibe la función, se experimento con diferentes de estos para obtener el mejor modelo según las métricas de nuestro interés.\n",
    "\n",
    "Para las metricas también se uso el paquete metrics de scikit-learn.\n",
    "\n",
    "Problemas:\n",
    " * Problemas en la visualización del árbol, debido al tamaño del arbol, no se lograba apreciar la estructura.\n",
    " * Problemas en la instalación del paquete graphviz para una mejor visualización del arbol.\n",
    "\n",
    " \n",
    "### Modelo SVM.\n",
    "\n",
    "Se uso el paquete de scikit-learn svm, y su función de entranimiento fit, también se realizo la busqueda de los mejores hyperparametros para la función, evaluando las métricas de interés.\n",
    "\n",
    "Ambos Modelos usados de scikit-learn se uso el paquete joblib, dump, algo nuevo aprendido.\n",
    "\n",
    "\n",
    "### Modelo Naive Bayes\n",
    "\n",
    "Implementación del modelo con numpy y pandas.\n",
    "2 modelos.\n",
    "* Modelos utilizando estimación de verosimilitud para el calculo de probabilidades condicionales, estimando medias y variancias de las clases.\n",
    "\n",
    "* Modelo utilando las probabilidades conjuntas.\n",
    "\n",
    "### Modelo Regresión Logistica\n",
    "\n",
    "Implementación del modelo utilizando tensorflow, y el algorimo de gradient descent, con las funciones sigomoid o softmax para el entrenamiento del modelo. Utilizando experimentación para los hyperparametros de regularización, lr, epochos asi como tambien el umbral de desición para las probabilidades, testeando con la función sigmoid y softmax. \n",
    "\n",
    "Export del modelo, investigación para realizarlo con tensorflow, se utilizo la función Saver para guardar la sessión y el grafo, para utilizarlo en el deployment de los modelos.\n",
    "\n",
    "### Deployment, Evaluación y prueba final.\n",
    "\n",
    "Utilizando el dataset de pruebas se realizó la evaluación final de los modelos, según nuestras metricas de interés se cumplió con el objetivo. Los modelos entrenados cumplen con las espectativas y son capaces de realizar predicciones acertadas en su mayoría.\n",
    "\n",
    "Para la elección y decisión del valor a predecir, se hizó una votación mayoritaria (ensemble learning) de los 4 modelos.\n",
    "\n",
    "### Otros archivos.\n",
    "Funciones globales separadas para obtener matriz de confusión y registrar bitacora de experimentación en archivo excel, para cada modelo.\n",
    "\n",
    "\n",
    "### Experiencias y Aprendizaje.\n",
    "* corección de errores.\n",
    "* Exportar modelos con tensorflow\n",
    "* Exportar modelos de scikit-learn\n",
    "* Algoritmo de naive bayes\n",
    "* Experimentación de modelos y elección de los mejores hyperparametros\n",
    "* Evaluar metricas de interés y elección del mejor modelo\n",
    "* La mayor parte del tiempo es en el analisis, limpieza y transformación de datos.\n",
    "* Problema que me surgió en todos los modelos, es que identificaban bien unicamente a las personas que no sobrevivieron, la exactitud era muy buena, pero por la naturaleza del dataset que está desbalanceado, volví varias veces a la experimentación y a la seleccion de las caracteristicas para obtener un modelo que predijera de igual forma las clases, sobrevivir o no sobrevivir, tratando de maximizar, la clase de personas que sobrevivieron es decir 1.\n",
    "\n",
    "### Recomendaciones\n",
    "* Analizar, limpiar y transormar los datos, aunque sea alto tedioso y lo que mas tiempo conlleva es lo mas importante para empezar a construir nuestros modelos y que estos sean de calidad.\n",
    "* Experimentar y evaluar los modelos con diferentes hyperparametros, evaluando las metricas de interes.\n",
    "* Utilizar técnicas de validación para mejorar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-folds y Cross Validation\n",
    "\n",
    "\n",
    "### Cross Validation\n",
    "Es una técnica que se utiliza para evaluar modelos e identificar cuando un modelo esta en underfitting e overfitting\n",
    "\n",
    "### K-folds\n",
    "\n",
    "consiste en tomar los datos originales y crear a partir de ellos dos conjuntos separados: un primer conjunto de entrenamiento (y prueba), y un segundo conjunto de validación.\n",
    "\n",
    "Luego, el conjunto de entrenamiento se va a dividir en k subconjuntos y, al momento de realizar el entrenamiento, se va a tomar cada k subconjunto como conjunto de prueba del modelo, mientras que el resto de los datos se tomará como conjunto de entrenamiento.\n",
    "\n",
    "Este proceso se repetirá k veces, y en cada iteración se seleccionará un conjunto de prueba diferente, mientras los datos restantes se emplearán, como se mencionó, como conjunto de entrenamiento. Una vez finalizadas las iteraciones, se calcula la precisión y el error para cada uno de los modelos producidos, y para obtener la precisión y el error final se calcula el promedio de los k modelos entrenados.\n",
    "\n",
    "Una vez se cuenta con esta precisión promedio para un modelo, se puede repetir entonces el procedimiento del Cross Validation para todos los demás modelos de clasificación que se estén evaluando, y se seleccionará al final aquel que produzca el mejor valor de precisión y menor error promedio.\n",
    "\n",
    "Entonces, puede utilizarse dicho modelo sobre el conjunto de validación generado en la primera parte, ya que, se supone, es este modelo el que mejor resultado en general ofreció durante la fase de entrenamiento\n",
    "\n",
    "\n",
    "### Como implementarlo en el proyecto\n",
    "\n",
    "Utilizando los datos de entrenamiento en conjunto con datos de validación, es decir uno solo en nuestro caso el 80% de los datos para realizar la validación. en cada k subconjunto se extrae el 20% del dataset para validación.\n",
    "\n",
    "En los modelos de scikit-learn, es bastante simple validar modelos por validación cruzada, se pasa directamente el parametro CV a la función fit. se crea la partición de los datos con el paquete model_selecction.KFOLDS y se itera sobre ellos para obtener el promedio de los k subconjutnos.\n",
    "\n",
    "En otras cirscunstancias como para el algoritmo de naive bayes o bien la forma en que se trabajo la regresión logistica con tensorflow, se crea una función para lograr el objetivo que es la división del dataset en k subconjutos, y evaluar cada subconjunto para obtener el promedio de ellos (según la metrica de interés).\n",
    "\n",
    "Por cada modelo evaluado se elige el mejor promedio de la metrica que se quiere evaluar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment con tensorflow\n",
    "\n",
    "**Utilizando SaveModel.**\n",
    "\n",
    "contiene un programa completo de TensorFlow, que incluye pesos y cálculo.\n",
    "\n",
    "**Pasos.**\n",
    "\n",
    "* Se crea una instancia de la clase tf.train.Saver()\n",
    "* Se guarda la session y el grafo, se crear los archivos que se utilizan para restaurar la session donde se requiera.\n",
    "* Se restaura la session donde se requiera utilizar. y tenemos el programa completo de tensorflow.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
